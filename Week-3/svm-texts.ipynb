{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Анализ текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Метод опорных векторов (`Support Vector Machine, SVM`) — один из видов линейных классификаторов. Функционал, который он оптимизирует, направлен на максимизацию ширины разделяющей полосы между классами. Из теории статистического обучения известно, что эта ширина тесно связана с обобщающей способностью алгоритма, а ее максимизация позволяет бороться с переобучением.\n",
    "\n",
    "Одна из причин популярности линейных методов заключается в том, что они хорошо работают на разреженных данных. Так называются выборки с большим количеством признаков, где на каждом объекте большинство признаков равны нулю. Разреженные данные возникают, например, при работе с текстами. Дело в том, что текст удобно кодировать с помощью \"мешка слов\" — формируется столько признаков, сколько всего уникальных слов встречается в текстах, и значение каждого признака равно числу вхождений в документ соответствующего слова. Ясно, что общее число различных слов в наборе текстов может достигать десятков тысяч, и при этом лишь небольшая их часть будет встречаться в одном конкретном тексте.\n",
    "\n",
    "Можно кодировать тексты хитрее, и записывать не количество вхождений слова в текст, а `TF-IDF`. Это показатель, который равен произведению двух чисел: `TF` (`term frequency`) и `IDF` (`inverse document frequency`). Первая равна отношению числа вхождений слова в документ к общей длине документа. Вторая величина зависит от того, в скольки документах выборки встречается это слово. Чем больше таких документов, тем меньше `IDF`. Таким образом, `TF-IDF` будет иметь высокое значение для тех слов, которые много раз встречаются в данном документе, и редко встречаются в остальных.\n",
    "\n",
    "## Данные\n",
    "Как мы уже говорили выше, линейные методы часто применяются для решения различных задач анализа текстов. В этом задании мы применим метод опорных векторов для определения того, к какой из тематик относится новость: атеизм или космос.\n",
    "\n",
    "## Реализация в Scikit-Learn\n",
    "Для начала вам потребуется загрузить данные. В этом задании мы воспользуемся одним из датасетов, доступных в `scikit-learn`'е — `20 newsgroups`. Для этого нужно воспользоваться модулем `datasets`:\n",
    "\n",
    "```python\n",
    "from sklearn import datasets\n",
    "\n",
    "newsgroups = datasets.fetch_20newsgroups(\n",
    "                    subset='all', \n",
    "                    categories=['alt.atheism', 'sci.space']\n",
    "             )\n",
    "```\n",
    "\n",
    "После выполнения этого кода массив с текстами будет находиться в поле `newsgroups.data`, номер класса — в поле `newsgroups.target`.\n",
    "\n",
    "Одна из сложностей работы с текстовыми данными состоит в том, что для них нужно построить числовое представление. Одним из способов нахождения такого представления является вычисление `TF-IDF`. В `Scikit-Learn` это реализовано в классе `sklearn.feature_extraction.text.TfidfVectorizer`. Преобразование обучающей выборки нужно делать с помощью функции `fit_transform`, тестовой — с помощью `transform`.\n",
    "\n",
    "Реализация `SVM`-классификатора находится в классе `sklearn.svm.SVC`. Веса каждого признака у обученного классификатора хранятся в поле `coef_`. Чтобы понять, какому слову соответствует i-й признак, можно воспользоваться методом `get_feature_names()` у `TfidfVectorizer`:\n",
    "\n",
    "```python\n",
    "feature_mapping = vectorizer.get_feature_names()\n",
    "print(feature_mapping[i])\n",
    "```\n",
    "\n",
    "Подбор параметров удобно делать с помощью класса `sklearn.grid_search.GridSearchCV` (При использовании библиотеки `scikit-learn` версии `18.0.1` `sklearn.model_selection.GridSearchCV`). Пример использования:\n",
    "\n",
    "```python\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cv = KFold(y.size, n_folds=5, shuffle=True, random_state=241)\n",
    "clf = svm.SVC(kernel='linear', random_state=241)\n",
    "gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(X, y)\n",
    "```\n",
    "\n",
    "При использовании библиотеки `scikit-learn` версии `18.0.1` и выше `KFold` задаётся немного по-другому:\n",
    "\n",
    "```python\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "```\n",
    "\n",
    "Первым аргументом в `GridSearchCV` передается классификатор, для которого будут подбираться значения параметров, вторым — словарь (`dict`), задающий сетку параметров для перебора. После того, как перебор окончен, можно проанализировать значения качества для всех значений параметров и выбрать наилучший вариант:\n",
    "\n",
    "```python\n",
    "for a in gs.grid_scores_:\n",
    "    # a.mean_validation_score — оценка качества по кросс-валидации\n",
    "    # a.parameters — значения параметров\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкция по выполнению\n",
    "### Шаг 1:\n",
    "Загрузите объекты из новостного датасета `20 newsgroups`, относящиеся к категориям \"космос\" и \"атеизм\" (инструкция приведена выше). Обратите внимание, что загрузка данных может занять несколько минут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(\n",
    "                    subset='all', \n",
    "                    categories=['alt.atheism', 'sci.space']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2:\n",
    "Вычислите `TF-IDF`-признаки для всех текстов. Обратите внимание, что в этом задании мы предлагаем вам вычислить `TF-IDF` по всем данным. При таком подходе получается, что признаки на обучающем множестве используют информацию из тестовой выборки — но такая ситуация вполне законна, поскольку мы не используем значения целевой переменной из теста. На практике нередко встречаются ситуации, когда признаки объектов тестовой выборки известны на момент обучения, и поэтому можно ими пользоваться при обучении алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(newsgroups.data)\n",
    "y = newsgroups.target\n",
    "\n",
    "feature_mapping = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3:\n",
    "Подберите минимальный лучший параметр `C` из множества $[10^{-5}, 10^{-4}, ... 10^4, 10^5]$ для `SVM` с линейным ядром (`kernel='linear'`) при помощи кросс-валидации по 5 блокам. Укажите параметр `random_state=241` и для `SVM`, и для `KFold`. В качестве меры качества используйте долю верных ответов (`accuracy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=241, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=241,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04, 1.e+05])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "clf = SVC(kernel='linear', random_state=241)\n",
    "gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4:\n",
    "Обучите `SVM` по всей выборке с оптимальным параметром `C`, найденным на предыдущем шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean validation score</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>{'C': 1e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950168</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.993281</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.993281</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.993281</td>\n",
       "      <td>{'C': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.993281</td>\n",
       "      <td>{'C': 1000.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.993281</td>\n",
       "      <td>{'C': 10000.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.993281</td>\n",
       "      <td>{'C': 100000.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean validation score       parameters\n",
       "0                0.552632     {'C': 1e-05}\n",
       "1                0.552632    {'C': 0.0001}\n",
       "2                0.552632     {'C': 0.001}\n",
       "3                0.552632      {'C': 0.01}\n",
       "4                0.950168       {'C': 0.1}\n",
       "5                0.993281       {'C': 1.0}\n",
       "6                0.993281      {'C': 10.0}\n",
       "7                0.993281     {'C': 100.0}\n",
       "8                0.993281    {'C': 1000.0}\n",
       "9                0.993281   {'C': 10000.0}\n",
       "10               0.993281  {'C': 100000.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'mean validation score': gs.cv_results_['mean_test_score'], 'parameters': gs.cv_results_['params']}\n",
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=241,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters: ', gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=241,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5:\n",
    "Найдите 10 слов с наибольшим абсолютным значением веса (веса хранятся в поле `coef_` у `svm.SVC`). Они являются ответом на это задание. Укажите эти слова через запятую или пробел, в нижнем регистре, в лексикографическом порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.2546899512384038, 'atheism'), (1.2491800073760075, 'atheists'), (1.130612344664901, 'bible'), (1.9203794002294938, 'god'), (1.0970936466401482, 'keith'), (1.2016111817520696, 'moon'), (1.13908083789883, 'religion'), (1.0293069271856938, 'sci'), (1.1801315951388633, 'sky'), (2.6631647884797105, 'space')]\n"
     ]
    }
   ],
   "source": [
    "weights = np.absolute(clf.coef_.toarray())\n",
    "\n",
    "max_weights = sorted(zip(weights[0], feature_mapping))[-10:]\n",
    "max_weights.sort(key=lambda x: x[1])\n",
    "print(max_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ans.txt\", \"w\") as f:\n",
    "    for w, c in max_weights[:-1]:\n",
    "        f.write(c)\n",
    "        f.write(' ')\n",
    "    f.write(max_weights[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ на каждое задание — текстовый файл, содержащий ответ в первой строчке. Обратите внимание, что отправляемые файлы не должны содержать перевод строки в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над тем, чтобы убрать это ограничение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
